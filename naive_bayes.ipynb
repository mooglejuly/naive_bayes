{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Applying Naive Bayes to Movies Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the age of data science, empiricial application of theory is vital. In this section, we implement the naive bayes algorithm based on the page 7 of https://web.stanford.edu/~jurafsky/slp3/6.pdf. We apply the algorithm on a set of movie reviews that are already labeled as positive or negative. The data set \"polarity_dataset v2.0\" of 1000 postive and 1000 negative samples can be found here: http://www.cs.cornell.edu/people/pabo/movie-review-data/.\n",
    "\n",
    "We divide the data into training and test sets. The training set contains 800 positive and 800 negative samples, and the test set contains 200 positive and 200 negative samples. We train the naive bayes algorithm on the training set. We use the popular nltk tokenizer, and throw away english stop words.\n",
    "\n",
    "Even with this quite naive algorithm, all of the positive precision, positive recall, negative precision, and negative recall are around 81% as follows:\n",
    "\n",
    "true positive count: 162\n",
    "false positive count: 39\n",
    "true negative count: 161\n",
    "false negative count: 38\n",
    "precision: 0.806\n",
    "recall: 0.810\n",
    "negative precision: 0.809\n",
    "negative recall: 0.805\n",
    "accuracy: 0.808\n",
    "\n",
    "The test is completely balanced, so achieving these ~81% metrics is significant compared to 50%, which we may get just by guessing one class all the time or purely randomizing. By this experiment, we empirically confirm that while naive bayes algorithm is very naive in theory, it can be quite useful in practice with quick and easy implementation.\n",
    "\n",
    "Please note that all the below code is original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_documents = []\n",
    "negative_documents = []\n",
    "\n",
    "import glob   \n",
    "path = 'movie_reviews_data/pos/*'   \n",
    "files=glob.glob(path)   \n",
    "for el in files:     \n",
    "    f=open(el, 'r')  \n",
    "    temp = f.readlines()   \n",
    "    positive_documents.append('. '.join(temp))\n",
    "    f.close() \n",
    "    \n",
    "path = 'movie_reviews_data/neg/*'   \n",
    "files=glob.glob(path)   \n",
    "for el in files:     \n",
    "    f=open(el, 'r')  \n",
    "    temp = f.readlines()   \n",
    "    negative_documents.append('. '.join(temp))\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "shuffle(positive_documents)\n",
    "shuffle(negative_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "800\n",
      "800\n",
      "800\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "train_to_test_ratio = 4\n",
    "num_train_positive = int(len(positive_documents) * train_to_test_ratio / float(train_to_test_ratio + 1.0))\n",
    "num_train_negative = int(len(negative_documents) * train_to_test_ratio / float(train_to_test_ratio + 1.0))\n",
    "\n",
    "print(num_train_positive)\n",
    "print(num_train_negative)\n",
    "\n",
    "positive_documents_train = positive_documents[:num_train_positive]\n",
    "negative_documents_train = negative_documents[:num_train_negative]\n",
    "\n",
    "positive_documents_test = positive_documents[num_train_positive:]\n",
    "negative_documents_test = negative_documents[num_train_negative:]\n",
    "\n",
    "print(len(positive_documents_train))\n",
    "print(len(negative_documents_train))\n",
    "print(len(positive_documents_test))\n",
    "print(len(negative_documents_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('.')\n",
    "\n",
    "def get_tokens_from_document(document):\n",
    "    tokens = nltk.word_tokenize(document)\n",
    "    tokens = [x for x in tokens if x not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, positive_documents_train, negative_documents_train):\n",
    "        self.positive_documents_train_ = positive_documents_train\n",
    "        self.negative_documents_train_ = negative_documents_train\n",
    "        self.positive_label_ = \"POSITIVE\"\n",
    "        self.negative_label_ = \"NEGATIVE\"\n",
    "        self.stop_words_ = set(stopwords.words('english'))\n",
    "        self.stop_words_.add('.')\n",
    "        \n",
    "    def initialize_vocab(self, max_vocab_size):\n",
    "        token_appearance_counter = collections.defaultdict(int)\n",
    "        positive_appearance_counter = collections.defaultdict(int)\n",
    "        negative_appearance_counter = collections.defaultdict(int)\n",
    "        \n",
    "        for positive_doc in self.positive_documents_train_:\n",
    "            tokens = get_tokens_from_document(positive_doc)\n",
    "            for t in tokens:\n",
    "                token_appearance_counter[t] += 1\n",
    "                positive_appearance_counter[t] += 1\n",
    "                \n",
    "        for negative_doc in self.negative_documents_train_:\n",
    "            tokens = get_tokens_from_document(negative_doc)\n",
    "            for t in tokens:\n",
    "                token_appearance_counter[t] += 1\n",
    "                negative_appearance_counter[t] += 1\n",
    "                \n",
    "        sorted_list = sorted(token_appearance_counter.items(), key=lambda x: x[1])\n",
    "        \n",
    "        self.vocab_ = [tup[0] for tup in sorted_list]\n",
    "        if (len(self.vocab_) > max_vocab_size):\n",
    "            self.vocab_ = self.vocab_[:max_vocab_size]\n",
    "            \n",
    "        self.positive_vocab_counter_ = {}\n",
    "        self.negative_vocab_counter_ = {}\n",
    "        \n",
    "        for word in self.vocab_:\n",
    "            self.positive_vocab_counter_[word] = positive_appearance_counter[word] if word in positive_appearance_counter else 0\n",
    "            self.negative_vocab_counter_[word] = negative_appearance_counter[word] if word in negative_appearance_counter else 0\n",
    "        \n",
    "        self.positive_loglikelihood_ = {}\n",
    "        self.negative_loglikelihood_ = {}\n",
    "        \n",
    "        temp_denom = sum(self.positive_vocab_counter_.values()) + len(self.positive_vocab_counter_)\n",
    "        for word, val in self.positive_vocab_counter_.items():\n",
    "            self.positive_loglikelihood_[word] = math.log((val + 1) / float(temp_denom))\n",
    "            \n",
    "        temp_denom = sum(self.negative_vocab_counter_.values()) + len(self.negative_vocab_counter_)\n",
    "        for word, val in self.negative_vocab_counter_.items():\n",
    "            self.negative_loglikelihood_[word] = math.log((val + 1) / float(temp_denom))\n",
    "\n",
    "    def initialize(self, max_vocab_size):\n",
    "        self.log_priors_ = {}\n",
    "        num_total_documents = len(self.positive_documents_train_) + len(self.negative_documents_train_)\n",
    "        self.log_priors_[self.positive_label_] = len(self.positive_documents_train_) / float(num_total_documents)\n",
    "        self.log_priors_[self.negative_label_] = len(self.negative_documents_train_) / float(num_total_documents)\n",
    "        \n",
    "        self.initialize_vocab(max_vocab_size)\n",
    "        \n",
    "    def classify(self, document):\n",
    "        tokens = get_tokens_from_document(document)\n",
    "        scores = {}\n",
    "        scores[self.positive_label_] = self.log_priors_[self.positive_label_]\n",
    "        scores[self.negative_label_] = self.log_priors_[self.negative_label_]\n",
    "        \n",
    "        for word in tokens:\n",
    "            if word in self.positive_loglikelihood_:\n",
    "                scores[self.positive_label_] += self.positive_loglikelihood_[word]\n",
    "            scores[self.negative_label_] += self.negative_loglikelihood_[word] if word in self.negative_loglikelihood_ else 0.0\n",
    "        \n",
    "        return 1 if scores[self.positive_label_] >= scores[self.negative_label_] else -1\n",
    "        \n",
    "\n",
    "nbc = NaiveBayesClassifier(positive_documents_train, negative_documents_train)\n",
    "nbc.initialize(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive_count = 0\n",
    "false_positive_count = 0\n",
    "true_negative_count = 0\n",
    "false_negative_count = 0\n",
    "\n",
    "for x in positive_documents_test:\n",
    "    if nbc.classify(x) == 1:\n",
    "        true_positive_count += 1\n",
    "    else:\n",
    "        false_negative_count += 1\n",
    "        \n",
    "for x in negative_documents_test:\n",
    "    if nbc.classify(x) == 1:\n",
    "        false_positive_count += 1\n",
    "    else:\n",
    "        true_negative_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive count: 162\n",
      "false positive count: 39\n",
      "true negative count: 161\n",
      "false negative count: 38\n",
      "precision: 0.805970149254\n",
      "recall: 0.81\n",
      "negative precision: 0.809045226131\n",
      "negative recall: 0.805\n",
      "accuracy: 0.8075\n"
     ]
    }
   ],
   "source": [
    "print 'true positive count: {}'.format(true_positive_count)\n",
    "print 'false positive count: {}'.format(false_positive_count)\n",
    "print 'true negative count: {}'.format(true_negative_count)\n",
    "print 'false negative count: {}'.format(false_negative_count)\n",
    "\n",
    "print 'precision: {}'.format(true_positive_count/float((true_positive_count + false_positive_count)))\n",
    "print 'recall: {}'.format(true_positive_count/float((true_positive_count + false_negative_count)))\n",
    "print 'negative precision: {}'.format(true_negative_count/float((true_negative_count + false_negative_count)))\n",
    "print 'negative recall: {}'.format(true_negative_count/float((true_negative_count + false_positive_count)))\n",
    "\n",
    "print 'accuracy: {}'.format((true_positive_count + true_negative_count) / \n",
    "                            float(true_positive_count + true_negative_count + false_positive_count + false_negative_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
